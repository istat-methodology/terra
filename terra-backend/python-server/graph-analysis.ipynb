{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from networkx.readwrite import json_graph\n",
    "import json\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import logging\n",
    "import logging.config\n",
    "from opencensus.ext.azure.log_exporter import AzureLogHandler\n",
    "import datetime\n",
    "\n",
    "from flask import Flask,request,Response\n",
    "from flask_cors import CORS\n",
    "from opencensus.ext.azure.trace_exporter import AzureExporter\n",
    "from opencensus.ext.flask.flask_middleware import FlaskMiddleware\n",
    "from opencensus.trace.samplers import ProbabilitySampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intra = pd.DataFrame()\n",
    "df_intra_trim = pd.DataFrame()\n",
    "df_extra = pd.DataFrame()\n",
    "df_extra_trim = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_SEP = \",\"\n",
    "PROD_DIGITS = 3  # number of digits to classify transports\n",
    "MAX_NODES = 70\n",
    "CHUNCK_SIZE = 5\n",
    "\n",
    "# COMEXT DATASETS\n",
    "INTRA_FILE = \"data\" + os.sep + \"cpa_intra.csv\"\n",
    "EXTRA_FILE = \"data\" + os.sep + \"tr_extra_ue.csv\"\n",
    "INTRA_TRIM_FILE = \"data\" + os.sep + \"cpa_trim.csv\"\n",
    "EXTRA_TRIM_FILE = \"data\" + os.sep + \"tr_extra_ue_trim.csv\"\n",
    "\n",
    "CRITERION = \"VALUE_IN_EUROS\"  # VALUE_IN_EUROS QUANTITY_IN_KG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s.%(msecs)03d %(levelname)s %(module)s - %(funcName)s: %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 12:51:51.146 WARNING 3646994727 - <module>: Application insights is not configured.\n"
     ]
    }
   ],
   "source": [
    "def is_application_insight_configured():\n",
    "    return (\n",
    "        os.getenv(\"APPINSIGHTS_INSTRUMENTATIONKEY\") != None\n",
    "        or os.getenv(\"APPLICATIONINSIGHTS_CONNECTION_STRING\") != None\n",
    "    )\n",
    "\n",
    "def ai_callback_function(envelope):\n",
    "    if os.getenv(\"CLOUD_ROLE\") != None:\n",
    "        envelope.tags[\"ai.cloud.role\"] = os.getenv(\"CLOUD_ROLE\")\n",
    "\n",
    "\n",
    "if is_application_insight_configured():\n",
    "    log_handler = AzureLogHandler()\n",
    "    log_handler.add_telemetry_processor(ai_callback_function)\n",
    "    logger.addHandler(log_handler)\n",
    "else:\n",
    "    logger.warning(\"Application insights is not configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_intra():\n",
    "    logger.info(\"[TERRA] Loading dataset INTRA...\")\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        INTRA_FILE,\n",
    "        low_memory=False,\n",
    "        dtype={\n",
    "            \"PRODUCT\": object,\n",
    "            \"FLOW\": np.int8,\n",
    "            \"PERIOD\": np.int32,\n",
    "            \"TRANSPORT_MODE\": np.int8,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    logger.info(\"[TERRA] Dataset INTRA loaded!\")\n",
    "    logger.info(f\"[TERRA] Dataset INTRA contains {df.shape[0]} records\")\n",
    "    return df\n",
    "\n",
    "def load_intra_trim():\n",
    "    def funcTrim(x):\n",
    "        return np.int32(x.replace(\"T\", \"0\"))\n",
    "\n",
    "    logger.info(\"[TERRA] Loading dataset INTRA TRIMESTER...\")\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        INTRA_TRIM_FILE,\n",
    "        low_memory=False,\n",
    "        converters={\"trimestre\": funcTrim},\n",
    "        dtype={\"cpa\": object, \"FLOW\": np.int8},\n",
    "    )\n",
    "    df = df[[\"DECLARANT_ISO\", \"PARTNER_ISO\", \"FLOW\", \"cpa\", \"trimestre\", \"val_cpa\"]]\n",
    "    df.columns = [\n",
    "        \"DECLARANT_ISO\",\n",
    "        \"PARTNER_ISO\",\n",
    "        \"FLOW\",\n",
    "        \"PRODUCT\",\n",
    "        \"PERIOD\",\n",
    "        \"VALUE_IN_EUROS\",\n",
    "    ]\n",
    "    df = df[df.PRODUCT.apply(lambda x: len(x.strip()) == PROD_DIGITS)]\n",
    "\n",
    "    logger.info(\"[TERRA] Dataset INTRA TRIMESTER loaded!\")\n",
    "    logger.info(f\"[TERRA] Dataset INTRA TRIMESTER contains {df.shape[0]} records\")\n",
    "    return df\n",
    "\n",
    "def load_extra():\n",
    "    logger.info(\"[TERRA] Loading dataset EXTRA...\")\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        EXTRA_FILE,\n",
    "        sep=FILE_SEP,\n",
    "        dtype={\n",
    "            \"PRODUCT_NSTR\": object,\n",
    "            \"FLOW\": np.int8,\n",
    "            \"PERIOD\": np.int32,\n",
    "            \"TRANSPORT_MODE\": np.int8,\n",
    "        },\n",
    "    )\n",
    "    df.columns = [\n",
    "        \"PRODUCT\",\n",
    "        \"DECLARANT_ISO\",\n",
    "        \"PARTNER_ISO\",\n",
    "        \"PERIOD\",\n",
    "        \"TRANSPORT_MODE\",\n",
    "        \"FLOW\",\n",
    "        \"VALUE_IN_EUROS\",\n",
    "        \"QUANTITY_IN_KG\",\n",
    "    ]\n",
    "\n",
    "    logger.info(\"[TERRA] Dataset EXTRA loaded!\")\n",
    "    logger.info(f\"[TERRA] Dataset EXTRA contains {df.shape[0]} records\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_extra_trim():\n",
    "    def funcTrim(x):\n",
    "        return np.int32(x.replace(\"T\", \"0\"))\n",
    "\n",
    "    logger.info(\"[TERRA] Loading dataset EXTRA TRIM...\")\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        EXTRA_TRIM_FILE,\n",
    "        low_memory=False,\n",
    "        converters={\"TRIMESTRE\": funcTrim},\n",
    "        dtype={\"PRODUCT_NSTR\": object, \"FLOW\": np.int8},\n",
    "    )\n",
    "    df = df[\n",
    "        [\n",
    "            \"DECLARANT_ISO\",\n",
    "            \"PARTNER_ISO\",\n",
    "            \"FLOW\",\n",
    "            \"PRODUCT_NSTR\",\n",
    "            \"TRANSPORT_MODE\",\n",
    "            \"TRIMESTRE\",\n",
    "            \"VALUE_IN_EUROS\",\n",
    "        ]\n",
    "    ]\n",
    "    df.columns = [\n",
    "        \"DECLARANT_ISO\",\n",
    "        \"PARTNER_ISO\",\n",
    "        \"FLOW\",\n",
    "        \"PRODUCT\",\n",
    "        \"TRANSPORT_MODE\",\n",
    "        \"PERIOD\",\n",
    "        \"VALUE_IN_EUROS\",\n",
    "    ]\n",
    "    df = df[df.PRODUCT.apply(lambda x: len(x.strip()) == PROD_DIGITS)]\n",
    "\n",
    "    logger.info(\"[TERRA] Dataset EXTRA TRIM loaded!\")\n",
    "    logger.info(f\"[TERRA] Dataset EXTRA TRIM contains {df.shape[0]} records\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a query to delete edges in the graph\n",
    "def build_edges_query(edges, flow):\n",
    "    \n",
    "    # Empty query object\n",
    "    query = []\n",
    "    \n",
    "    for edge in edges:\n",
    "        if flow == 1:\n",
    "            PARTNER_ISO = edge[\"from\"]\n",
    "            DECLARANT_ISO = edge[\"to\"]\n",
    "        else:\n",
    "            DECLARANT_ISO = edge[\"from\"]\n",
    "            PARTNER_ISO = edge[\"to\"]\n",
    "\n",
    "        exclude = str(edge[\"exclude\"])\n",
    "\n",
    "        # Graph without TRANSPORTS\n",
    "        if \"-99\" in exclude:\n",
    "            query.append(\n",
    "                \"(DECLARANT_ISO == '\"\n",
    "                + DECLARANT_ISO\n",
    "                + \"' & PARTNER_ISO == '\"\n",
    "                + PARTNER_ISO\n",
    "                + \"' )\"\n",
    "            )\n",
    "        else:\n",
    "            query.append(\n",
    "                \"((DECLARANT_ISO == '\"\n",
    "                + DECLARANT_ISO\n",
    "                + \"' & PARTNER_ISO == '\"\n",
    "                + PARTNER_ISO\n",
    "                + \"' & TRANSPORT_MODE in \"\n",
    "                + exclude\n",
    "                + \"))\"\n",
    "            )\n",
    "    return \"not (\" + (\"|\".join(query)) + \")\"\n",
    "\n",
    "\n",
    "# Remove from the transport dataframe the subset NOT containing edges\n",
    "def remove_edges(df_comext, edges, flow):\n",
    "    query = build_edges_query(edges, flow)\n",
    "    df_comext = df_comext.query(query)\n",
    "    return df_comext\n",
    "\n",
    "\n",
    "def build_metrics(graph):\n",
    "    logger.info(\"[TERRA] Calculating graph metrics...\")\n",
    "\n",
    "    in_deg = nx.in_degree_centrality(graph)\n",
    "    graph_metrics = {}\n",
    "    vulnerability = {}\n",
    "\n",
    "    for k, v in in_deg.items():\n",
    "        if v != 0:\n",
    "            vulnerability[k] = 1 - v\n",
    "        else:\n",
    "            vulnerability[k] = 0\n",
    "        \n",
    "        graph_metrics = {\n",
    "            \"degree_centrality\": nx.degree_centrality(graph),\n",
    "            \"density\": nx.density(graph),\n",
    "            \"vulnerability\": vulnerability,\n",
    "            \"exportation strenght\": {\n",
    "                a: b for a, b in graph.out_degree(weight=\"weight\")\n",
    "            },\n",
    "            \"hubness\": nx.closeness_centrality(graph.to_undirected()),\n",
    "        }\n",
    "    \n",
    "    logger.info(\"[TERRA] Graph metrics ready!\")\n",
    "    return graph_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "### Extract graph table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_graph_table(\n",
    "    period,\n",
    "    percentage,\n",
    "    transports,\n",
    "    flow,\n",
    "    product,\n",
    "    criterion,\n",
    "    selectedEdges,\n",
    "    df_comext,\n",
    "):\n",
    "\n",
    "    logger.info(\"[TERRA] Preparing graph table...\")\n",
    "\n",
    "    # Extract FLOW\n",
    "    df_comext = df_comext[\n",
    "        df_comext[\"FLOW\"] == flow\n",
    "    ]\n",
    "    \n",
    "    # Extract PERIOD\n",
    "    if period is not None:\n",
    "        period = np.int32(period)\n",
    "        df_comext = df_comext[\n",
    "            df_comext[\"PERIOD\"] == period\n",
    "        ]\n",
    "    \n",
    "    # Extract TRANSPORTS\n",
    "    if transports is not None:\n",
    "        df_comext = df_comext[\n",
    "            df_comext[\"TRANSPORT_MODE\"].isin(transports)\n",
    "        ]\n",
    "\n",
    "    # Extract PRODUCT\n",
    "    if product is not None:\n",
    "        df_comext = df_comext[\n",
    "            df_comext[\"PRODUCT\"] == product\n",
    "        ]\n",
    "\n",
    "    # Extract EDGES\n",
    "    if selectedEdges is not None:\n",
    "        \n",
    "        NUMBER_OF_EDGES_CHUNKS = len(selectedEdges) // (CHUNCK_SIZE)\n",
    "\n",
    "        for i in range(NUMBER_OF_EDGES_CHUNKS):\n",
    "            selectedEdges_i = selectedEdges[\n",
    "                i * CHUNCK_SIZE : (i + 1) * CHUNCK_SIZE\n",
    "            ]\n",
    "            df_comext = remove_edges(\n",
    "                df_comext, selectedEdges_i, flow\n",
    "            )\n",
    "        selectedEdges_i = selectedEdges[\n",
    "            NUMBER_OF_EDGES_CHUNKS * CHUNCK_SIZE : len(selectedEdges)\n",
    "        ]\n",
    "        \n",
    "        if len(selectedEdges_i) > 0:\n",
    "            df_comext = remove_edges(\n",
    "                df_comext, selectedEdges_i, flow\n",
    "            )\n",
    "\n",
    "    # Aggregate on DECLARANT_ISO and PARTNER_ISO and sort on criterion (VALUE or QUANTITY)\n",
    "    df_comext = (\n",
    "        df_comext.groupby([\"DECLARANT_ISO\", \"PARTNER_ISO\"])\n",
    "        .sum()\n",
    "        .reset_index()[[\"DECLARANT_ISO\", \"PARTNER_ISO\", criterion]]\n",
    "    )\n",
    "    df_comext = df_comext.sort_values(\n",
    "        criterion, ascending=False\n",
    "    )\n",
    "    \n",
    "    # Cut graph on bottom percentile\n",
    "    if percentage is not None:\n",
    "        SUM = df_comext[criterion].sum()\n",
    "        df_comext = df_comext[\n",
    "            df_comext[criterion].cumsum(skipna=False) / SUM * 100 < percentage\n",
    "        ]\n",
    "    \n",
    "    logger.info(\"[TERRA] Graph table ready!\")\n",
    "\n",
    "    return df_comext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build graph\n",
    "Build the graph and the metrics based on the filtered table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(tab4graph, pos_ini, weight_flag, flow, criterion):\n",
    "    \n",
    "    logger.info(\"[TERRA] Building GRAPH...\")\n",
    "\n",
    "    # Create an empty graph\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Assign roles according to flow (IMPORT or EXPORT)\n",
    "    if flow == 1:\n",
    "        country_from = \"PARTNER_ISO\"\n",
    "        country_to = \"DECLARANT_ISO\"\n",
    "    else:\n",
    "        country_from = \"DECLARANT_ISO\"\n",
    "        country_to = \"PARTNER_ISO\"\n",
    "\n",
    "    # Build the Graph with edges and nodes, if the Graph is weighted\n",
    "    # assign the weight VALUE or QUANTITY depending on the criterion chosen to sort the market and perform the cut\n",
    "    if weight_flag == True:\n",
    "        weight = criterion\n",
    "        WEIGHT_SUM = tab4graph[weight].sum()\n",
    "        edges = [\n",
    "            (i, j, w / WEIGHT_SUM)\n",
    "            for i, j, w in tab4graph.loc[:, [country_from, country_to, weight]].values\n",
    "        ]\n",
    "    else:\n",
    "        edges = [\n",
    "            (i, j, 1) for i, j in tab4graph.loc[:, [country_from, country_to]].values\n",
    "        ]\n",
    "\n",
    "    # Add weigthed edges to the graph\n",
    "    G.add_weighted_edges_from(edges)\n",
    "\n",
    "    attribute = {}\n",
    "    for i, j, w in edges:\n",
    "        attribute[(i, j)] = {criterion: int(w * WEIGHT_SUM)}\n",
    "\n",
    "    nx.set_edge_attributes(G, attribute)\n",
    "\n",
    "    # Build metrics\n",
    "    graph_metrics = build_metrics(G)\n",
    "\n",
    "    # Json graph\n",
    "    GG = json_graph.node_link_data(G)\n",
    "    \n",
    "    k_layout = 5\n",
    "    pos_ini = {}\n",
    "    random.seed(88)\n",
    "    for node in GG[\"nodes\"]:\n",
    "        x = random.uniform(0, 1)\n",
    "        y = random.uniform(0, 1)\n",
    "        pos_ini[node[\"id\"]] = np.array([x, y])\n",
    "\n",
    "    try:\n",
    "        coord = nx.spring_layout(\n",
    "            G, k=k_layout / math.sqrt(G.order()), pos=pos_ini, iterations=200\n",
    "         )\n",
    "        coord = nx.spring_layout(\n",
    "            G, k=k_layout / math.sqrt(G.order()), pos=coord, iterations=50\n",
    "        )  # stable solution\n",
    "\n",
    "    except:\n",
    "        return None, None, None\n",
    "\n",
    "    # Create a dataframe with graph nodes coordinates\n",
    "    df_coord = pd.DataFrame.from_dict(coord, orient=\"index\")\n",
    "    df_coord.columns = [\"x\", \"y\"]\n",
    "\n",
    "    df = pd.DataFrame(GG[\"nodes\"])\n",
    "    df.columns = [\"label\"]\n",
    "    df[\"id\"] = np.arange(df.shape[0])\n",
    "    df = df[[\"id\", \"label\"]]\n",
    "    out = pd.merge(df, df_coord, left_on=\"label\", right_index=True)\n",
    "    dict_nodes = out.T.to_dict().values()\n",
    "\n",
    "    dfe = pd.DataFrame(GG[\"links\"])[[\"source\", \"target\", \"weight\", criterion]]\n",
    "    res = dfe.set_index(\"source\").join(\n",
    "        out[[\"label\", \"id\"]].set_index(\"label\"), on=\"source\", how=\"left\"\n",
    "    )\n",
    "    res.columns = [\"target\", \"source_id\", \"weight\", criterion]\n",
    "    res2 = res.set_index(\"target\").join(\n",
    "        out[[\"label\", \"id\"]].set_index(\"label\"), on=\"target\", how=\"left\"\n",
    "    )\n",
    "    res2.columns = [\"weight\", criterion, \"from\", \"to\"]\n",
    "    res2.reset_index(drop=True, inplace=True)\n",
    "    dict_edges = res2.T.to_dict().values()\n",
    "\n",
    "    new_dict = {\n",
    "        \"nodes\": list(dict_nodes),\n",
    "        \"edges\": list(dict_edges),\n",
    "        \"metriche\": graph_metrics,\n",
    "    }\n",
    "\n",
    "    JSON = json.dumps(new_dict)\n",
    "\n",
    "    logger.info(\"[TERRA] GRAPH built!\")\n",
    "\n",
    "    return coord, JSON, G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonpos2coord(jsonpos):\n",
    "    logger.info(\"[TERRA] JSON2COORDINATES...\")\n",
    "    coord = {}\n",
    "    for id, x, y in pd.DataFrame.from_dict(jsonpos[\"nodes\"])[\n",
    "        [\"label\", \"x\", \"y\"]\n",
    "    ].values:\n",
    "        coord[id] = np.array([x, y])\n",
    "    logger.info(\"[TERRA] JSON2COORDINATES done!\")\n",
    "    return coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    try:\n",
    "        df_intra = load_intra()\n",
    "        df_intra_trim = load_intra_trim()\n",
    "        df_extra = load_extra()\n",
    "        df_extra_trim = load_extra_trim()\n",
    "    except:\n",
    "        logger.info(\"[TERRA] Files not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 12:51:51.334 INFO 17239207 - load_intra: [TERRA] Loading dataset INTRA...\n",
      "2024-01-03 12:52:02.769 INFO 17239207 - load_intra: [TERRA] Dataset INTRA loaded!\n",
      "2024-01-03 12:52:02.769 INFO 17239207 - load_intra: [TERRA] Dataset INTRA contains 15101732 records\n",
      "2024-01-03 12:52:02.769 INFO 17239207 - load_extra: [TERRA] Loading dataset EXTRA...\n",
      "2024-01-03 12:52:18.206 INFO 17239207 - load_extra: [TERRA] Dataset EXTRA loaded!\n",
      "2024-01-03 12:52:18.206 INFO 17239207 - load_extra: [TERRA] Dataset EXTRA contains 22035020 records\n"
     ]
    }
   ],
   "source": [
    "df_intra = load_intra()\n",
    "df_extra = load_extra()\n",
    "df_intra_trim = load_intra_trim()\n",
    "df_extra_trim = load_extra_trim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flask setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nazure_exporter.add_telemetry_processor(ai_callback_function)\\nif is_application_insight_configured():\\n    middleware = FlaskMiddleware(\\n        app,\\n        exporter=azure_exporter,\\n        sampler=ProbabilitySampler(rate=1.0),\\n    ) \\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app, resources=r'/*')\n",
    "\n",
    "\"\"\" \n",
    "azure_exporter.add_telemetry_processor(ai_callback_function)\n",
    "if is_application_insight_configured():\n",
    "    middleware = FlaskMiddleware(\n",
    "        app,\n",
    "        exporter=azure_exporter,\n",
    "        sampler=ProbabilitySampler(rate=1.0),\n",
    "    ) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph extra month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/graphExtraMonth\", methods=[\"POST\", \"GET\"])\n",
    "def graphExtraMonth():\n",
    "    if request.method == \"POST\":\n",
    "        logger.info(\"[TERRA] Graph extra month...\")\n",
    "\n",
    "        # Currently criterio is set to \"VALUE_IN_EUROS\" \n",
    "        criterion = CRITERION\n",
    "\n",
    "        # User request\n",
    "        jsonRequest = dict(request.json)\n",
    "        \n",
    "        #Get PERCENTAGE\n",
    "        percentage = int(jsonRequest[\"tg_perc\"])\n",
    "        \n",
    "        #Get PERIOD\n",
    "        period = int(jsonRequest[\"tg_period\"])\n",
    "        \n",
    "        #Get NODES COORDINATES\n",
    "        pos = jsonRequest[\"pos\"]\n",
    "        if pos == \"None\" or len(pos[\"nodes\"]) == 0:\n",
    "            pos = None\n",
    "        else:\n",
    "            # Build nodes coordinates according to previous graph\n",
    "            pos = jsonpos2coord(pos)\n",
    "\n",
    "        # 0:Unknown 1:Sea 2:Rail 3:Road 4Air 5:Post 7:Fixed Mechanism 8:Inland Waterway 9:Self Propulsion\n",
    "        transports = jsonRequest[\"listaMezzi\"]  # [0,1,2,3,4,5,7,8,9]\n",
    "        \n",
    "        #Get FLOW\n",
    "        flow = int(jsonRequest[\"flow\"])\n",
    "        \n",
    "        #Get PRODUCT\n",
    "        product = str(jsonRequest[\"product\"])\n",
    "        \n",
    "        #Get WEIGHT_FLAG (currently hardcoded)\n",
    "        weight_flag = bool(jsonRequest[\"weight_flag\"])\n",
    "        \n",
    "        # This key is set in the scenario analysis\n",
    "        selectedTransportEdges = jsonRequest[\"selezioneMezziEdges\"]\n",
    "        if selectedTransportEdges == \"None\":\n",
    "            selectedTransportEdges = None\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        #Build graph table\n",
    "        tab4graph = extract_graph_table(\n",
    "            period,\n",
    "            percentage,\n",
    "            transports,\n",
    "            flow,\n",
    "            product,\n",
    "            criterion,\n",
    "            selectedTransportEdges,\n",
    "            df_extra,\n",
    "        )\n",
    "        logger.info(f\"[TERRA] Graph shape {tab4graph.shape}\")\n",
    "        \n",
    "        # Check the size of the graph\n",
    "        NUM_NODI = len(\n",
    "            set(tab4graph[\"DECLARANT_ISO\"]).union(set(tab4graph[\"PARTNER_ISO\"]))\n",
    "        )\n",
    "        if NUM_NODI > MAX_NODES:\n",
    "            logger.info(f\"[TERRA] Graph is too wide!\")\n",
    "            return json.dumps({\"STATUS\": \"05\"})\n",
    "        \n",
    "        # Build graph\n",
    "        pos, JSON, G = build_graph(tab4graph, pos, weight_flag, flow, criterion)\n",
    "\n",
    "        if pos is None:\n",
    "            if JSON is None:\n",
    "                logger.info(f\"[TERRA] Graph is empty!\")\n",
    "                return json.dumps({\"STATUS\": \"06\"})\n",
    "        \n",
    "        resp = Response(response=JSON, status=200, mimetype=\"application/json\")\n",
    "        logger.info(\"[TERRA] Graph extra month done!\")\n",
    "        return resp\n",
    "\n",
    "    else:\n",
    "        logger.info(\"[TERRA] Error in HTTP request method!\")\n",
    "        return str(\"only post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph extra trimester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/graphExtraTrim\", methods=[\"POST\", \"GET\"])\n",
    "def graphExtraTrim():\n",
    "    if request.method == \"POST\":\n",
    "        logger.info(\"[TERRA] Graph extra trimester...\")\n",
    "\n",
    "        # Currently criterio is set to \"VALUE_IN_EUROS\" \n",
    "        criterion = CRITERION\n",
    "\n",
    "        # User request\n",
    "        jsonRequest = dict(request.json)\n",
    "        \n",
    "        #Get PERCENTAGE\n",
    "        percentage = int(jsonRequest[\"tg_perc\"])\n",
    "        \n",
    "        #Get PERIOD\n",
    "        period = int(jsonRequest[\"tg_period\"])\n",
    "        \n",
    "        #Get NODES COORDINATES\n",
    "        pos = jsonRequest[\"pos\"]\n",
    "        if pos == \"None\" or len(pos[\"nodes\"]) == 0:\n",
    "            pos = None\n",
    "        else:\n",
    "            # Build nodes coordinates according to previous graph\n",
    "            pos = jsonpos2coord(pos)\n",
    "\n",
    "        # 0:Unknown 1:Sea 2:Rail 3:Road 4Air 5:Post 7:Fixed Mechanism 8:Inland Waterway 9:Self Propulsion\n",
    "        transports = jsonRequest[\"listaMezzi\"]  # [0,1,2,3,4,5,7,8,9]\n",
    "        \n",
    "        #Get FLOW\n",
    "        flow = int(jsonRequest[\"flow\"])\n",
    "        \n",
    "        #Get PRODUCT\n",
    "        product = str(jsonRequest[\"product\"])\n",
    "        \n",
    "        #Get WEIGHT_FLAG (currently hardcoded)\n",
    "        weight_flag = bool(jsonRequest[\"weight_flag\"])\n",
    "        \n",
    "        # This key is set in the scenario analysis\n",
    "        selectedTransportEdges = jsonRequest[\"selezioneMezziEdges\"]\n",
    "        if selectedTransportEdges == \"None\":\n",
    "            selectedTransportEdges = None\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        #Build graph table\n",
    "        tab4graph = extract_graph_table(\n",
    "            period,\n",
    "            percentage,\n",
    "            transports,\n",
    "            flow,\n",
    "            product,\n",
    "            criterion,\n",
    "            selectedTransportEdges,\n",
    "            df_extra_trim,\n",
    "        )\n",
    "        logger.info(f\"[TERRA] Graph shape {tab4graph.shape}\")\n",
    "        \n",
    "        # Check the size of the graph\n",
    "        NUM_NODI = len(\n",
    "            set(tab4graph[\"DECLARANT_ISO\"]).union(set(tab4graph[\"PARTNER_ISO\"]))\n",
    "        )\n",
    "        if NUM_NODI > MAX_NODES:\n",
    "            logger.info(f\"[TERRA] Graph is too wide!\")\n",
    "            return json.dumps({\"STATUS\": \"05\"})\n",
    "        \n",
    "        # Build graph\n",
    "        pos, JSON, G = build_graph(tab4graph, pos, weight_flag, flow, criterion)\n",
    "\n",
    "        if pos is None:\n",
    "            if JSON is None:\n",
    "                logger.info(f\"[TERRA] Graph is empty!\")\n",
    "                return json.dumps({\"STATUS\": \"06\"})\n",
    "        \n",
    "        resp = Response(response=JSON, status=200, mimetype=\"application/json\")\n",
    "        logger.info(\"[TERRA] Graph extra trimester done!\")\n",
    "        return resp\n",
    "\n",
    "    else:\n",
    "        logger.info(\"[TERRA] Error in HTTP request method!\")\n",
    "        return str(\"only post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph intra month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/graphIntraMonth', methods=['POST','GET'])\n",
    "def graphIntraMonth():\n",
    "    if request.method == 'POST':\n",
    "        logger.info(\"[TERRA] Graph intra month...\")\n",
    "\n",
    "        # Currently criterio is set to \"VALUE_IN_EUROS\" \n",
    "        criterion = CRITERION\n",
    "\n",
    "        # User request\n",
    "        jsonRequest = dict(request.json)\n",
    "        \n",
    "        #Get PERCENTAGE\n",
    "        percentage = int(jsonRequest[\"tg_perc\"])\n",
    "        \n",
    "        #Get PERIOD\n",
    "        period = int(jsonRequest[\"tg_period\"])\n",
    "        \n",
    "        #Get NODES COORDINATES\n",
    "        pos = jsonRequest[\"pos\"]\n",
    "        if pos == \"None\" or len(pos[\"nodes\"]) == 0:\n",
    "            pos = None\n",
    "        else:\n",
    "            # Build nodes coordinates according to previous graph\n",
    "            pos = jsonpos2coord(pos)\n",
    "\n",
    "        #Get FLOW\n",
    "        flow = int(jsonRequest[\"flow\"])\n",
    "        \n",
    "        #Get PRODUCT\n",
    "        product = str(jsonRequest[\"product\"])\n",
    "        \n",
    "        #Get WEIGHT_FLAG (currently hardcoded)\n",
    "        weight_flag = bool(jsonRequest[\"weight_flag\"])\n",
    "        \n",
    "        # This key is set in the scenario analysis\n",
    "        selectedTransportEdges = jsonRequest[\"selezioneMezziEdges\"]\n",
    "        if selectedTransportEdges == \"None\":\n",
    "            selectedTransportEdges = None\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        #Build graph table (without transports)\n",
    "        tab4graph = extract_graph_table(\n",
    "            period,\n",
    "            percentage,\n",
    "            None,\n",
    "            flow,\n",
    "            product,\n",
    "            criterion,\n",
    "            selectedTransportEdges,\n",
    "            df_intra,\n",
    "        )\n",
    "        logger.info(f\"[TERRA] Graph shape {tab4graph.shape}\")\n",
    "        \n",
    "        # Check the size of the graph\n",
    "        NUM_NODI = len(\n",
    "            set(tab4graph[\"DECLARANT_ISO\"]).union(set(tab4graph[\"PARTNER_ISO\"]))\n",
    "        )\n",
    "        if NUM_NODI > MAX_NODES:\n",
    "            logger.info(f\"[TERRA] Graph is too wide!\")\n",
    "            return json.dumps({\"STATUS\": \"05\"})\n",
    "        \n",
    "        # Build graph\n",
    "        pos, JSON, G = build_graph(tab4graph, pos, weight_flag, flow, criterion)\n",
    "\n",
    "        if pos is None:\n",
    "            if JSON is None:\n",
    "                logger.info(f\"[TERRA] Graph is empty!\")\n",
    "                return json.dumps({\"STATUS\": \"06\"})\n",
    "        \n",
    "        resp = Response(response=JSON, status=200, mimetype=\"application/json\")\n",
    "        logger.info(\"[TERRA] Graph intra month done!\")\n",
    "        return resp\n",
    "    else:\n",
    "        logger.info(\"[TERRA] Error in HTTP request method!\")\n",
    "        return str(\"only post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph intra trimester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/graphIntraTrim', methods=['POST','GET'])\n",
    "def graphIntraTrim():\n",
    "    if request.method == 'POST':\n",
    "        logger.info(\"[TERRA] Graph intra trimester...\")\n",
    "\n",
    "        # Currently criterio is set to \"VALUE_IN_EUROS\" \n",
    "        criterion = CRITERION\n",
    "\n",
    "        # User request\n",
    "        jsonRequest = dict(request.json)\n",
    "        \n",
    "        #Get PERCENTAGE\n",
    "        percentage = int(jsonRequest[\"tg_perc\"])\n",
    "        \n",
    "        #Get PERIOD\n",
    "        period = int(jsonRequest[\"tg_period\"])\n",
    "        \n",
    "        #Get NODES COORDINATES\n",
    "        pos = jsonRequest[\"pos\"]\n",
    "        if pos == \"None\" or len(pos[\"nodes\"]) == 0:\n",
    "            pos = None\n",
    "        else:\n",
    "            # Build nodes coordinates according to previous graph\n",
    "            pos = jsonpos2coord(pos)\n",
    "\n",
    "        #Get FLOW\n",
    "        flow = int(jsonRequest[\"flow\"])\n",
    "        \n",
    "        #Get PRODUCT\n",
    "        product = str(jsonRequest[\"product\"])\n",
    "        \n",
    "        #Get WEIGHT_FLAG (currently hardcoded)\n",
    "        weight_flag = bool(jsonRequest[\"weight_flag\"])\n",
    "        \n",
    "        # This key is set in the scenario analysis\n",
    "        selectedTransportEdges = jsonRequest[\"selezioneMezziEdges\"]\n",
    "        if selectedTransportEdges == \"None\":\n",
    "            selectedTransportEdges = None\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        #Build graph table (without transports)\n",
    "        tab4graph = extract_graph_table(\n",
    "            period,\n",
    "            percentage,\n",
    "            None,\n",
    "            flow,\n",
    "            product,\n",
    "            criterion,\n",
    "            selectedTransportEdges,\n",
    "            df_intra_trim,\n",
    "        )\n",
    "        logger.info(f\"[TERRA] Graph shape {tab4graph.shape}\")\n",
    "        \n",
    "        # Check the size of the graph\n",
    "        NUM_NODI = len(\n",
    "            set(tab4graph[\"DECLARANT_ISO\"]).union(set(tab4graph[\"PARTNER_ISO\"]))\n",
    "        )\n",
    "        if NUM_NODI > MAX_NODES:\n",
    "            logger.info(f\"[TERRA] Graph is too wide!\")\n",
    "            return json.dumps({\"STATUS\": \"05\"})\n",
    "        \n",
    "        # Build graph\n",
    "        pos, JSON, G = build_graph(tab4graph, pos, weight_flag, flow, criterion)\n",
    "\n",
    "        if pos is None:\n",
    "            if JSON is None:\n",
    "                logger.info(f\"[TERRA] Graph is empty!\")\n",
    "                return json.dumps({\"STATUS\": \"06\"})\n",
    "        \n",
    "        resp = Response(response=JSON, status=200, mimetype=\"application/json\")\n",
    "        logger.info(\"[TERRA] Graph intra trimester done!\")\n",
    "        return resp\n",
    "    else:\n",
    "        logger.info(\"[TERRA] Error in HTTP request method!\")\n",
    "        return str(\"only post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Python server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 12:52:18.378 INFO _internal - _log: \u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5500\n",
      " * Running on http://192.168.1.198:5500\n",
      "2024-01-03 12:52:18.378 INFO _internal - _log: \u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "2024-01-03 12:52:51.835 INFO _internal - _log: 127.0.0.1 - - [03/Jan/2024 12:52:51] \"OPTIONS /graphExtraMonth HTTP/1.1\" 200 -\n",
      "2024-01-03 12:52:52.083 INFO 1721788469 - graphExtraMonth: [TERRA] Graph extra month...\n",
      "2024-01-03 12:52:52.091 INFO 1457142449 - extract_graph_table: [TERRA] Preparing graph table...\n",
      "2024-01-03 12:52:54.309 INFO 1457142449 - extract_graph_table: [TERRA] Graph table ready!\n",
      "2024-01-03 12:52:54.309 INFO 1721788469 - graphExtraMonth: [TERRA] Graph shape (197, 3)\n",
      "2024-01-03 12:52:54.315 INFO 3536347606 - build_graph: [TERRA] Building GRAPH...\n",
      "2024-01-03 12:52:54.315 INFO 1748329586 - build_metrics: [TERRA] Calculating graph metrics...\n",
      "2024-01-03 12:52:55.146 INFO 1748329586 - build_metrics: [TERRA] Graph metrics ready!\n",
      "2024-01-03 12:52:55.430 INFO 3536347606 - build_graph: [TERRA] GRAPH built!\n",
      "2024-01-03 12:52:55.437 INFO 1721788469 - graphExtraMonth: [TERRA] Graph extra month done!\n",
      "2024-01-03 12:52:55.437 INFO _internal - _log: 127.0.0.1 - - [03/Jan/2024 12:52:55] \"POST /graphExtraMonth HTTP/1.1\" 200 -\n",
      "2024-01-03 12:53:01.208 INFO _internal - _log: 127.0.0.1 - - [03/Jan/2024 12:53:01] \"OPTIONS /graphIntraMonth HTTP/1.1\" 200 -\n",
      "2024-01-03 12:53:01.520 INFO 2070582950 - graphIntraMonth: [TERRA] Graph intra month...\n",
      "2024-01-03 12:53:01.531 INFO 1457142449 - extract_graph_table: [TERRA] Preparing graph table...\n",
      "2024-01-03 12:53:02.840 INFO 1457142449 - extract_graph_table: [TERRA] Graph table ready!\n",
      "2024-01-03 12:53:02.843 INFO 2070582950 - graphIntraMonth: [TERRA] Graph shape (279, 3)\n",
      "2024-01-03 12:53:02.843 INFO 3536347606 - build_graph: [TERRA] Building GRAPH...\n",
      "2024-01-03 12:53:02.853 INFO 1748329586 - build_metrics: [TERRA] Calculating graph metrics...\n",
      "2024-01-03 12:53:03.594 INFO 1748329586 - build_metrics: [TERRA] Graph metrics ready!\n",
      "2024-01-03 12:53:03.820 INFO 3536347606 - build_graph: [TERRA] GRAPH built!\n",
      "2024-01-03 12:53:03.824 INFO 2070582950 - graphIntraMonth: [TERRA] Graph intra month done!\n",
      "2024-01-03 12:53:03.824 INFO _internal - _log: 127.0.0.1 - - [03/Jan/2024 12:53:03] \"POST /graphIntraMonth HTTP/1.1\" 200 -\n",
      "2024-01-03 12:53:06.888 INFO _internal - _log: 127.0.0.1 - - [03/Jan/2024 12:53:06] \"OPTIONS /graphIntraMonth HTTP/1.1\" 200 -\n",
      "2024-01-03 12:53:07.206 INFO 2070582950 - graphIntraMonth: [TERRA] Graph intra month...\n",
      "2024-01-03 12:53:07.214 INFO 2925370660 - jsonpos2coord: [TERRA] JSON2COORDINATES...\n",
      "2024-01-03 12:53:07.222 INFO 2925370660 - jsonpos2coord: [TERRA] JSON2COORDINATES done!\n",
      "2024-01-03 12:53:07.222 INFO 1457142449 - extract_graph_table: [TERRA] Preparing graph table...\n",
      "2024-01-03 12:53:08.421 INFO 1457142449 - extract_graph_table: [TERRA] Graph table ready!\n",
      "2024-01-03 12:53:08.421 INFO 2070582950 - graphIntraMonth: [TERRA] Graph shape (259, 3)\n",
      "2024-01-03 12:53:08.421 INFO 3536347606 - build_graph: [TERRA] Building GRAPH...\n",
      "2024-01-03 12:53:08.431 INFO 1748329586 - build_metrics: [TERRA] Calculating graph metrics...\n",
      "2024-01-03 12:53:08.992 INFO 1748329586 - build_metrics: [TERRA] Graph metrics ready!\n",
      "2024-01-03 12:53:09.211 INFO 3536347606 - build_graph: [TERRA] GRAPH built!\n",
      "2024-01-03 12:53:09.211 INFO 2070582950 - graphIntraMonth: [TERRA] Graph intra month done!\n",
      "2024-01-03 12:53:09.211 INFO _internal - _log: 127.0.0.1 - - [03/Jan/2024 12:53:09] \"POST /graphIntraMonth HTTP/1.1\" 200 -\n",
      "2024-01-03 12:55:03.555 INFO _internal - _log: 127.0.0.1 - - [03/Jan/2024 12:55:03] \"OPTIONS /graphIntraMonth HTTP/1.1\" 200 -\n",
      "2024-01-03 12:55:03.808 INFO 2070582950 - graphIntraMonth: [TERRA] Graph intra month...\n",
      "2024-01-03 12:55:03.816 INFO 1457142449 - extract_graph_table: [TERRA] Preparing graph table...\n",
      "2024-01-03 12:55:04.523 INFO 1457142449 - extract_graph_table: [TERRA] Graph table ready!\n",
      "2024-01-03 12:55:04.523 INFO 2070582950 - graphIntraMonth: [TERRA] Graph shape (279, 3)\n",
      "2024-01-03 12:55:04.523 INFO 3536347606 - build_graph: [TERRA] Building GRAPH...\n",
      "2024-01-03 12:55:04.531 INFO 1748329586 - build_metrics: [TERRA] Calculating graph metrics...\n",
      "2024-01-03 12:55:04.995 INFO 1748329586 - build_metrics: [TERRA] Graph metrics ready!\n",
      "2024-01-03 12:55:05.118 INFO 3536347606 - build_graph: [TERRA] GRAPH built!\n",
      "2024-01-03 12:55:05.118 INFO 2070582950 - graphIntraMonth: [TERRA] Graph intra month done!\n",
      "2024-01-03 12:55:05.118 INFO _internal - _log: 127.0.0.1 - - [03/Jan/2024 12:55:05] \"POST /graphIntraMonth HTTP/1.1\" 200 -\n",
      "2024-01-03 12:55:13.524 INFO _internal - _log: 127.0.0.1 - - [03/Jan/2024 12:55:13] \"OPTIONS /graphExtraMonth HTTP/1.1\" 200 -\n",
      "2024-01-03 12:55:13.834 INFO 1721788469 - graphExtraMonth: [TERRA] Graph extra month...\n",
      "2024-01-03 12:55:13.834 INFO 1457142449 - extract_graph_table: [TERRA] Preparing graph table...\n",
      "2024-01-03 12:55:16.099 INFO 1457142449 - extract_graph_table: [TERRA] Graph table ready!\n",
      "2024-01-03 12:55:16.107 INFO 1721788469 - graphExtraMonth: [TERRA] Graph shape (197, 3)\n",
      "2024-01-03 12:55:16.107 INFO 3536347606 - build_graph: [TERRA] Building GRAPH...\n",
      "2024-01-03 12:55:16.115 INFO 1748329586 - build_metrics: [TERRA] Calculating graph metrics...\n",
      "2024-01-03 12:55:16.945 INFO 1748329586 - build_metrics: [TERRA] Graph metrics ready!\n",
      "2024-01-03 12:55:17.206 INFO 3536347606 - build_graph: [TERRA] GRAPH built!\n",
      "2024-01-03 12:55:17.207 INFO 1721788469 - graphExtraMonth: [TERRA] Graph extra month done!\n",
      "2024-01-03 12:55:17.207 INFO _internal - _log: 127.0.0.1 - - [03/Jan/2024 12:55:17] \"POST /graphExtraMonth HTTP/1.1\" 200 -\n",
      "2024-01-03 12:55:25.277 INFO _internal - _log: 127.0.0.1 - - [03/Jan/2024 12:55:25] \"OPTIONS /graphExtraMonth HTTP/1.1\" 200 -\n",
      "2024-01-03 12:55:25.588 INFO 1721788469 - graphExtraMonth: [TERRA] Graph extra month...\n",
      "2024-01-03 12:55:25.588 INFO 2925370660 - jsonpos2coord: [TERRA] JSON2COORDINATES...\n",
      "2024-01-03 12:55:25.596 INFO 2925370660 - jsonpos2coord: [TERRA] JSON2COORDINATES done!\n",
      "2024-01-03 12:55:25.604 INFO 1457142449 - extract_graph_table: [TERRA] Preparing graph table...\n",
      "2024-01-03 12:55:27.812 INFO 1457142449 - extract_graph_table: [TERRA] Graph table ready!\n",
      "2024-01-03 12:55:27.814 INFO 1721788469 - graphExtraMonth: [TERRA] Graph shape (191, 3)\n",
      "2024-01-03 12:55:27.816 INFO 3536347606 - build_graph: [TERRA] Building GRAPH...\n",
      "2024-01-03 12:55:27.819 INFO 1748329586 - build_metrics: [TERRA] Calculating graph metrics...\n",
      "2024-01-03 12:55:28.446 INFO 1748329586 - build_metrics: [TERRA] Graph metrics ready!\n",
      "2024-01-03 12:55:28.671 INFO 3536347606 - build_graph: [TERRA] GRAPH built!\n",
      "2024-01-03 12:55:28.671 INFO 1721788469 - graphExtraMonth: [TERRA] Graph extra month done!\n",
      "2024-01-03 12:55:28.680 INFO _internal - _log: 127.0.0.1 - - [03/Jan/2024 12:55:28] \"POST /graphExtraMonth HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    IP='0.0.0.0'\n",
    "    port=5500\n",
    "    app.run(host=IP, port=port)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
